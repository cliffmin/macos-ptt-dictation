{"text": " this project I'm wanting to change behavior so I want this effectively to just be a way for me to be a some client command that's also installed globally say I did PV store or save or whatever is best here and what will happen is it'll wait for me to paste the conversation which is going to be probably pretty long and it'll do a validation that it is indeed a agent's conversation and if it's not it won't do anything yeah it'll output maybe yeah this is not a conversation and if it is then I wanted to store in the DB the conversation and following best practice it'll I don't know somehow this is fine like let's keep it simple", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.72, "text": " this project I'm wanting to change behavior so I want this effectively to", "tokens": [50363, 428, 1628, 314, 1101, 10291, 284, 1487, 4069, 523, 314, 765, 428, 6840, 284, 50849], "temperature": 0.0, "avg_logprob": -0.3256980961766736, "compression_ratio": 1.2, "no_speech_prob": 0.17797225713729858}, {"id": 1, "seek": 0, "start": 9.72, "end": 26.6, "text": " just be a way for me to be a", "tokens": [50849, 655, 307, 257, 835, 329, 502, 284, 307, 257, 51693], "temperature": 0.0, "avg_logprob": -0.3256980961766736, "compression_ratio": 1.2, "no_speech_prob": 0.17797225713729858}, {"id": 2, "seek": 2660, "start": 26.6, "end": 40.52, "text": " some client command that's also installed globally say I did PV store", "tokens": [50363, 617, 5456, 3141, 326, 338, 635, 6589, 18309, 910, 314, 750, 31392, 3650, 51059], "temperature": 0.0, "avg_logprob": -0.18611408163000037, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.0890001431107521}, {"id": 3, "seek": 2660, "start": 40.52, "end": 48.36, "text": " or save or whatever is best here and what will happen is it'll wait for me", "tokens": [51059, 393, 3613, 393, 4232, 318, 1266, 994, 290, 644, 481, 1645, 318, 340, 1183, 4043, 329, 502, 51451], "temperature": 0.0, "avg_logprob": -0.18611408163000037, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.0890001431107521}, {"id": 4, "seek": 2660, "start": 48.36, "end": 55.88, "text": " to paste the conversation which is going to be probably pretty long and it'll do", "tokens": [51451, 284, 17008, 262, 5273, 543, 318, 1016, 284, 307, 2192, 2495, 890, 290, 340, 1183, 466, 51827], "temperature": 0.0, "avg_logprob": -0.18611408163000037, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.0890001431107521}, {"id": 5, "seek": 5588, "start": 55.88, "end": 68.16, "text": " a validation that it is indeed a agent's conversation and if it's not it", "tokens": [50363, 257, 21201, 326, 340, 318, 5600, 257, 5797, 338, 5273, 290, 611, 340, 338, 407, 340, 50977], "temperature": 0.0, "avg_logprob": -0.20232276427440155, "compression_ratio": 1.4854368932038835, "no_speech_prob": 0.07263273745775223}, {"id": 6, "seek": 5588, "start": 68.16, "end": 81.56, "text": " won't do anything yeah it'll output maybe yeah this is not a conversation and if", "tokens": [50977, 1839, 470, 466, 1997, 10194, 340, 1183, 5072, 3863, 10194, 428, 318, 407, 257, 5273, 290, 611, 51647], "temperature": 0.0, "avg_logprob": -0.20232276427440155, "compression_ratio": 1.4854368932038835, "no_speech_prob": 0.07263273745775223}, {"id": 7, "seek": 8156, "start": 81.56, "end": 90.60000000000001, "text": " it is then I wanted to store in the DB the conversation and following best", "tokens": [50363, 340, 318, 788, 314, 2227, 284, 3650, 287, 262, 20137, 262, 5273, 290, 1708, 1266, 50815], "temperature": 0.0, "avg_logprob": -0.2910235121443465, "compression_ratio": 1.2956521739130435, "no_speech_prob": 0.15995065867900848}, {"id": 8, "seek": 8156, "start": 90.60000000000001, "end": 110.68, "text": " practice it'll I don't know somehow this is fine like let's keep it simple", "tokens": [50815, 3357, 340, 1183, 314, 836, 470, 760, 7599, 428, 318, 3734, 588, 1309, 338, 1394, 340, 2829, 51819], "temperature": 0.0, "avg_logprob": -0.2910235121443465, "compression_ratio": 1.2956521739130435, "no_speech_prob": 0.15995065867900848}], "language": "en"}